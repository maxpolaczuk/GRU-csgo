{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team win history GRU\n",
    "\n",
    "Choose two teams, the history will first be displayed as (for example) 0,1,0,..,1,0 etc.\n",
    "Then these are compiled and a GRU is made to predict the probability of future win of that team against a challenger..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (82,83,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv('matchdata.csv',encoding = \"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need a function that pulls out only a certain teams data:\n",
    "\n",
    "def team_data(team): # probably by index...\n",
    "    df = dat.loc[(dat.ix[:,3] == team) |  (dat.ix[:,4] == team) ]\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def win_series(team1,team2):\n",
    "    wins = []\n",
    "    losses = []\n",
    "    \n",
    "    # find only games where team 1 and team 2 are playing\n",
    "    df = dat.loc[((dat.ix[:,3] == team1) |  (dat.ix[:,4] == team1) ) & ((dat.ix[:,3] == team2) |  (dat.ix[:,4] == team2) )]\n",
    "    df = df.reset_index(drop = True) \n",
    "    # now for each row find if they won or lost: winning team == team1\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        if (df.ix[i,5] == team1):\n",
    "            # they won\n",
    "            wins.append(1)\n",
    "            losses.append(0)\n",
    "        elif (df.ix[i,5] == team2):\n",
    "            # they lost\n",
    "            wins.append(0)\n",
    "            losses.append(1)\n",
    "        else:\n",
    "            # can't find them\n",
    "            wins.append('?')\n",
    "    \n",
    "    # now reverse the win vector to be oldest to newest\n",
    "    wins = np.flipud(wins)\n",
    "    ins= wins[:len(wins)-1]\n",
    "    targs = wins[1:len(wins)] \n",
    "    lins = np.array(losses[:len(wins)-1]) \n",
    "    ltargs = np.array(losses[1:len(wins)])\n",
    "    \n",
    "    return ins, targs, lins,ltargs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' sequence padding code '''\n",
    "from __future__ import absolute_import\n",
    "# -*- coding: utf-8 -*-\n",
    "import random\n",
    "from six.moves import range\n",
    "\n",
    "\n",
    "def pad_sequences(sequences, maxlen=None, dtype='int32',\n",
    "                  padding='pre', truncating='pre', value=0.):\n",
    "    '''Pads each sequence to the same length:\n",
    "    the length of the longest sequence.\n",
    "\n",
    "    If maxlen is provided, any sequence longer\n",
    "    than maxlen is truncated to maxlen.\n",
    "    Truncation happens off either the beginning (default) or\n",
    "    the end of the sequence.\n",
    "\n",
    "    Supports post-padding and pre-padding (default).\n",
    "\n",
    "    # Arguments\n",
    "        sequences: list of lists where each element is a sequence\n",
    "        maxlen: int, maximum length\n",
    "        dtype: type to cast the resulting sequence.\n",
    "        padding: 'pre' or 'post', pad either before or after each sequence.\n",
    "        truncating: 'pre' or 'post', remove values from sequences larger than\n",
    "            maxlen either in the beginning or in the end of the sequence\n",
    "        value: float, value to pad the sequences to the desired value.\n",
    "\n",
    "    # Returns\n",
    "        x: numpy array with dimensions (number_of_sequences, maxlen)\n",
    "    '''\n",
    "    lengths = [len(s) for s in sequences]\n",
    "\n",
    "    nb_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "\n",
    "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if len(s) == 0:\n",
    "            continue  # empty list was found\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
    "                             (trunc.shape[1:], idx, sample_shape))\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, T, XL , TL = win_series('EnVyUs','fnatic')\n",
    "X1, T1, XL1 , TL1 = win_series('EnVyUs','Natus Vincere')\n",
    "X2, T2, XL2 , TL2 = win_series('EnVyUs','Luminosity')\n",
    "X3, T3, XL3 , TL3 = win_series('EnVyUs','Virtus.pro')\n",
    "X4, T4, XL4 , TL4 = win_series('EnVyUs','TSM')\n",
    "X5, T5, XL5 , TL5 = win_series('EnVyUs','Astralis')\n",
    "X6, T6, XL6 , TL6 = win_series('EnVyUs','NiP')\n",
    "\n",
    "\n",
    "# now zero pad all to be the same shape:\n",
    "\n",
    "\n",
    "\n",
    "# combine into an array:\n",
    "\n",
    "ins =  pad_sequences(np.array([X.tolist(),X1.tolist(),X2.tolist(),X3.tolist(),X4.tolist(),X5.tolist(),X6.tolist()]) )\n",
    "targs = pad_sequences(np.array([T.tolist(),T1.tolist(),T2.tolist(),T3.tolist(),T4.tolist(),T5.tolist(),T6.tolist()]) )\n",
    "\n",
    "lins =  pad_sequences(np.array([XL.tolist(),XL1.tolist(),XL2.tolist(),XL3.tolist(),XL4.tolist(),XL5.tolist(),XL6.tolist()]) )\n",
    "\n",
    "ltargs = pad_sequences(np.array([TL.tolist(),TL1.tolist(),TL2.tolist(),TL3.tolist(),TL4.tolist(),TL5.tolist(),TL6.tolist()]) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' split into testing and training sets '''\n",
    "len(ins)\n",
    "split = 0.7\n",
    "Ntrain = int(round(len(ins)*split,0))\n",
    "\n",
    "train_ins = ins[:Ntrain]\n",
    "test_ins = ins[Ntrain:]\n",
    "train_T = targs[:Ntrain]\n",
    "test_T = targs[Ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 1, 1, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the model of GRU\n",
    "# Keras imports \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM,GRU, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_neurons = 1\n",
    "hidden_neurons = 1\n",
    " \n",
    "model = Sequential()  \n",
    "model.add(GRU(output_dim=hidden_neurons, input_dim= in_neurons, return_sequences=True, consume_less='gpu')) \n",
    "model.add(GRU(output_dim=hidden_neurons, input_dim= hidden_neurons, return_sequences=True, consume_less='gpu')) \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer= 'adam' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s - loss: 0.5619 - val_loss: 0.3815\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s - loss: 0.5619 - val_loss: 0.3812\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s - loss: 0.5618 - val_loss: 0.3811\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s - loss: 0.5617 - val_loss: 0.3809\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s - loss: 0.5616 - val_loss: 0.3807\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s - loss: 0.5615 - val_loss: 0.3806\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s - loss: 0.5615 - val_loss: 0.3805\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s - loss: 0.5614 - val_loss: 0.3804\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s - loss: 0.5614 - val_loss: 0.3801\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s - loss: 0.5613 - val_loss: 0.3799\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s - loss: 0.5612 - val_loss: 0.3798\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s - loss: 0.5611 - val_loss: 0.3797\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s - loss: 0.5611 - val_loss: 0.3794\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s - loss: 0.5610 - val_loss: 0.3792\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s - loss: 0.5610 - val_loss: 0.3792\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s - loss: 0.5609 - val_loss: 0.3789\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s - loss: 0.5609 - val_loss: 0.3789\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s - loss: 0.5608 - val_loss: 0.3788\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s - loss: 0.5607 - val_loss: 0.3785\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s - loss: 0.5607 - val_loss: 0.3785\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s - loss: 0.5605 - val_loss: 0.3783\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s - loss: 0.5605 - val_loss: 0.3781\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s - loss: 0.5605 - val_loss: 0.3778\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s - loss: 0.5604 - val_loss: 0.3776\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s - loss: 0.5603 - val_loss: 0.3774\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s - loss: 0.5603 - val_loss: 0.3772\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s - loss: 0.5602 - val_loss: 0.3769\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s - loss: 0.5601 - val_loss: 0.3768\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s - loss: 0.5601 - val_loss: 0.3766\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s - loss: 0.5600 - val_loss: 0.3764\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s - loss: 0.5600 - val_loss: 0.3762\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s - loss: 0.5599 - val_loss: 0.3761\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s - loss: 0.5599 - val_loss: 0.3760\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s - loss: 0.5598 - val_loss: 0.3757\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s - loss: 0.5597 - val_loss: 0.3755\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s - loss: 0.5597 - val_loss: 0.3753\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s - loss: 0.5597 - val_loss: 0.3750\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s - loss: 0.5596 - val_loss: 0.3749\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s - loss: 0.5596 - val_loss: 0.3746\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s - loss: 0.5594 - val_loss: 0.3744\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s - loss: 0.5594 - val_loss: 0.3743\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s - loss: 0.5593 - val_loss: 0.3741\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s - loss: 0.5593 - val_loss: 0.3738\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s - loss: 0.5592 - val_loss: 0.3736\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s - loss: 0.5592 - val_loss: 0.3733\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s - loss: 0.5591 - val_loss: 0.3733\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s - loss: 0.5590 - val_loss: 0.3730\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s - loss: 0.5590 - val_loss: 0.3727\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s - loss: 0.5589 - val_loss: 0.3724\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s - loss: 0.5588 - val_loss: 0.3722\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s - loss: 0.5588 - val_loss: 0.3719\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s - loss: 0.5587 - val_loss: 0.3718\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s - loss: 0.5587 - val_loss: 0.3715\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s - loss: 0.5586 - val_loss: 0.3713\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s - loss: 0.5586 - val_loss: 0.3712\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s - loss: 0.5585 - val_loss: 0.3710\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s - loss: 0.5585 - val_loss: 0.3709\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s - loss: 0.5585 - val_loss: 0.3705\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s - loss: 0.5583 - val_loss: 0.3703\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s - loss: 0.5583 - val_loss: 0.3702\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s - loss: 0.5582 - val_loss: 0.3700\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s - loss: 0.5581 - val_loss: 0.3697\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s - loss: 0.5581 - val_loss: 0.3696\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s - loss: 0.5581 - val_loss: 0.3692\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s - loss: 0.5580 - val_loss: 0.3690\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s - loss: 0.5579 - val_loss: 0.3689\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s - loss: 0.5578 - val_loss: 0.3687\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s - loss: 0.5579 - val_loss: 0.3683\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s - loss: 0.5577 - val_loss: 0.3681\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s - loss: 0.5577 - val_loss: 0.3678\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s - loss: 0.5576 - val_loss: 0.3677\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s - loss: 0.5575 - val_loss: 0.3675\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s - loss: 0.5575 - val_loss: 0.3673\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s - loss: 0.5575 - val_loss: 0.3670\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s - loss: 0.5574 - val_loss: 0.3667\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s - loss: 0.5573 - val_loss: 0.3666\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s - loss: 0.5573 - val_loss: 0.3663\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s - loss: 0.5572 - val_loss: 0.3661\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s - loss: 0.5571 - val_loss: 0.3660\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s - loss: 0.5571 - val_loss: 0.3659\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s - loss: 0.5570 - val_loss: 0.3655\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s - loss: 0.5570 - val_loss: 0.3652\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s - loss: 0.5569 - val_loss: 0.3649\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s - loss: 0.5569 - val_loss: 0.3646\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s - loss: 0.5568 - val_loss: 0.3646\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s - loss: 0.5568 - val_loss: 0.3642\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s - loss: 0.5567 - val_loss: 0.3642\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s - loss: 0.5567 - val_loss: 0.3638\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s - loss: 0.5566 - val_loss: 0.3635\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s - loss: 0.5565 - val_loss: 0.3635\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s - loss: 0.5564 - val_loss: 0.3632\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s - loss: 0.5564 - val_loss: 0.3629\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s - loss: 0.5563 - val_loss: 0.3626\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s - loss: 0.5563 - val_loss: 0.3626\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s - loss: 0.5562 - val_loss: 0.3625\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s - loss: 0.5561 - val_loss: 0.3622\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s - loss: 0.5561 - val_loss: 0.3619\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s - loss: 0.5560 - val_loss: 0.3616\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s - loss: 0.5559 - val_loss: 0.3614\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s - loss: 0.5559 - val_loss: 0.3614\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s - loss: 0.5558 - val_loss: 0.3612\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s - loss: 0.5557 - val_loss: 0.3610\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s - loss: 0.5557 - val_loss: 0.3608\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s - loss: 0.5556 - val_loss: 0.3607\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s - loss: 0.5557 - val_loss: 0.3602\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s - loss: 0.5555 - val_loss: 0.3599\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s - loss: 0.5554 - val_loss: 0.3597\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s - loss: 0.5554 - val_loss: 0.3594\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s - loss: 0.5554 - val_loss: 0.3591\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s - loss: 0.5553 - val_loss: 0.3588\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s - loss: 0.5552 - val_loss: 0.3587\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s - loss: 0.5551 - val_loss: 0.3585\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s - loss: 0.5551 - val_loss: 0.3585\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s - loss: 0.5550 - val_loss: 0.3582\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s - loss: 0.5550 - val_loss: 0.3579\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s - loss: 0.5549 - val_loss: 0.3578\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s - loss: 0.5548 - val_loss: 0.3576\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s - loss: 0.5548 - val_loss: 0.3574\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s - loss: 0.5547 - val_loss: 0.3571"
     ]
    }
   ],
   "source": [
    "''' train this fella '''\n",
    "model.fit(np.reshape(train_ins,(len(train_ins),52,1) ), np.reshape(train_T,(len(train_ins),52,1) ), batch_size=1, nb_epoch = 500, validation_split=0.1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Real  Predicted\n",
      "0      0  -0.023531\n",
      "1      0  -0.012929\n",
      "2      0  -0.013260\n",
      "3      0  -0.012094\n",
      "4      0  -0.011867\n",
      "5      0  -0.011678\n",
      "6      0  -0.011608\n",
      "7      0  -0.011570\n",
      "8      0  -0.011554\n",
      "9      0  -0.011545\n",
      "10     0  -0.011541\n",
      "11     0  -0.011539\n",
      "12    -1   0.056036\n",
      "13    -1  -0.037172\n",
      "14     1  -0.068246\n",
      "15    -1   0.055354\n",
      "16    -1  -0.047476\n",
      "17     1  -0.072815\n",
      "18     1   0.054957\n",
      "19     1   0.053395\n",
      "20     1   0.062464\n",
      "21    -1   0.062969\n",
      "22     1  -0.020749\n",
      "23    -1   0.060462\n",
      "24    -1  -0.036619\n",
      "25    -1  -0.067337\n",
      "26     1  -0.094572\n",
      "27     1   0.054746\n",
      "28     1   0.051846\n",
      "29     1   0.062352\n",
      "30    -1   0.062848\n",
      "31     1  -0.020830\n",
      "32     1   0.060454\n",
      "33     1   0.057426\n",
      "34    -1   0.063124\n",
      "35    -1  -0.021545\n",
      "36     1  -0.060305\n",
      "37     1   0.055978\n",
      "38     1   0.054335\n",
      "39    -1   0.062597\n",
      "40    -1  -0.022350\n",
      "41    -1  -0.060743\n",
      "42     1  -0.089847\n",
      "43    -1   0.054879\n",
      "44    -1  -0.051485\n",
      "45    -1  -0.074615\n",
      "46    -1  -0.099579\n",
      "47    -1  -0.112396\n",
      "48    -1  -0.120486\n",
      "49    -1  -0.125097\n",
      "50     1  -0.127789\n",
      "51    -1   0.053744\n"
     ]
    }
   ],
   "source": [
    "Tshape = np.shape(train_ins)[1]\n",
    "predicted = model.predict(np.reshape(test_ins,(np.shape(test_T)[0],Tshape,1)))\n",
    "\n",
    "preds = pd.DataFrame()\n",
    "preds['Real'] = np.reshape(test_T[1],(Tshape) )\n",
    "preds['Predicted'] = np.reshape(predicted[1],(Tshape) )\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INP = win_series('EnVyUs','G2')\n",
    "predicted = model.predict(np.reshape(np.array(INP) , (2,len(INP[0]),1)) )[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00726403],\n",
       "       [ 0.01320932],\n",
       "       [ 0.54285729],\n",
       "       [ 0.54242665],\n",
       "       [ 0.54244822],\n",
       "       [ 0.54244715],\n",
       "       [ 0.49628255],\n",
       "       [ 0.45058441],\n",
       "       [ 0.40618879],\n",
       "       [ 0.36383224],\n",
       "       [ 0.32410753],\n",
       "       [ 0.5488987 ],\n",
       "       [ 0.54221153],\n",
       "       [ 0.54245901],\n",
       "       [ 0.54244661],\n",
       "       [ 0.49628198]], dtype=float32)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Real  Predicted\n",
      "0      1   0.542201\n",
      "1      1   0.542459\n",
      "2      1   0.542447\n",
      "3      1   0.542447\n",
      "4      1   0.542447\n",
      "5      0   0.496283\n",
      "6      0   0.450584\n",
      "7      1   0.546245\n",
      "8      1   0.542259\n",
      "9      0   0.496094\n",
      "10     1   0.544562\n",
      "11     1   0.542341\n",
      "12     1   0.542453\n",
      "13     1   0.542447\n",
      "14     1   0.542447\n"
     ]
    }
   ],
   "source": [
    "INP = win_series('EnVyUs','HellRaisers')\n",
    "\n",
    "predicted = model.predict(np.reshape(np.array(INP) , (2,len(INP[0]),1)) )[0]\n",
    "TTshape = len(predicted)\n",
    "preds = pd.DataFrame()\n",
    "preds['Real'] = np.reshape(INP[0],(TTshape) )\n",
    "preds['Predicted'] = np.reshape(predicted,(TTshape) )\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
