{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team win history GRU\n",
    "\n",
    "Choose two teams, the history will first be displayed as (for example) 0,1,0,..,1,0 etc.\n",
    "Then these are compiled and a GRU is made to predict the probability of future win of that team against a challenger..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (82,83,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv('matchdata.csv',encoding = \"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need a function that pulls out only a certain teams data:\n",
    "\n",
    "def team_data(team): # probably by index...\n",
    "    df = dat.loc[(dat.ix[:,3] == team) |  (dat.ix[:,4] == team) ]\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def win_series(team1,team2):\n",
    "    wins = []\n",
    "    losses = []\n",
    "    \n",
    "    # find only games where team 1 and team 2 are playing\n",
    "    df = dat.loc[((dat.ix[:,3] == team1) |  (dat.ix[:,4] == team1) ) & ((dat.ix[:,3] == team2) |  (dat.ix[:,4] == team2) )]\n",
    "    df = df.reset_index(drop = True) \n",
    "    # now for each row find if they won or lost: winning team == team1\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        if (df.ix[i,5] == team1):\n",
    "            # they won\n",
    "            wins.append(1)\n",
    "            losses.append(0)\n",
    "        elif (df.ix[i,5] == team2):\n",
    "            # they lost\n",
    "            wins.append(0)\n",
    "            losses.append(1)\n",
    "        else:\n",
    "            # can't find them\n",
    "            wins.append('?')\n",
    "    \n",
    "    # now reverse the win vector to be oldest to newest\n",
    "    wins = np.flipud(wins)\n",
    "    ins= wins[:len(wins)-1]\n",
    "    targs = wins[1:len(wins)] \n",
    "    lins = np.array(losses[:len(wins)-1]) \n",
    "    ltargs = np.array(losses[1:len(wins)])\n",
    "    \n",
    "    return ins, targs, lins,ltargs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' sequence padding code '''\n",
    "from __future__ import absolute_import\n",
    "# -*- coding: utf-8 -*-\n",
    "import random\n",
    "from six.moves import range\n",
    "\n",
    "\n",
    "def pad_sequences(sequences, maxlen=None, dtype='int32',\n",
    "                  padding='pre', truncating='pre', value=0.):\n",
    "    '''Pads each sequence to the same length:\n",
    "    the length of the longest sequence.\n",
    "\n",
    "    If maxlen is provided, any sequence longer\n",
    "    than maxlen is truncated to maxlen.\n",
    "    Truncation happens off either the beginning (default) or\n",
    "    the end of the sequence.\n",
    "\n",
    "    Supports post-padding and pre-padding (default).\n",
    "\n",
    "    # Arguments\n",
    "        sequences: list of lists where each element is a sequence\n",
    "        maxlen: int, maximum length\n",
    "        dtype: type to cast the resulting sequence.\n",
    "        padding: 'pre' or 'post', pad either before or after each sequence.\n",
    "        truncating: 'pre' or 'post', remove values from sequences larger than\n",
    "            maxlen either in the beginning or in the end of the sequence\n",
    "        value: float, value to pad the sequences to the desired value.\n",
    "\n",
    "    # Returns\n",
    "        x: numpy array with dimensions (number_of_sequences, maxlen)\n",
    "    '''\n",
    "    lengths = [len(s) for s in sequences]\n",
    "\n",
    "    nb_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "\n",
    "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if len(s) == 0:\n",
    "            continue  # empty list was found\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
    "                             (trunc.shape[1:], idx, sample_shape))\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, T, XL , TL = win_series('EnVyUs','fnatic')\n",
    "X1, T1, XL1 , TL1 = win_series('EnVyUs','Natus Vincere')\n",
    "X2, T2, XL2 , TL2 = win_series('EnVyUs','Luminosity')\n",
    "X3, T3, XL3 , TL3 = win_series('EnVyUs','Virtus.pro')\n",
    "X4, T4, XL4 , TL4 = win_series('EnVyUs','TSM')\n",
    "X5, T5, XL5 , TL5 = win_series('EnVyUs','Astralis')\n",
    "X6, T6, XL6 , TL6 = win_series('EnVyUs','NiP')\n",
    "\n",
    "\n",
    "# now zero pad all to be the same shape:\n",
    "\n",
    "\n",
    "\n",
    "# combine into an array:\n",
    "\n",
    "ins =  pad_sequences(np.array([X.tolist(),X1.tolist(),X2.tolist(),X3.tolist(),X4.tolist(),X5.tolist(),X6.tolist()]) )\n",
    "targs = pad_sequences(np.array([T.tolist(),T1.tolist(),T2.tolist(),T3.tolist(),T4.tolist(),T5.tolist(),T6.tolist()]) )\n",
    "\n",
    "lins =  pad_sequences(np.array([XL.tolist(),XL1.tolist(),XL2.tolist(),XL3.tolist(),XL4.tolist(),XL5.tolist(),XL6.tolist()]) )\n",
    "\n",
    "ltargs = pad_sequences(np.array([TL.tolist(),TL1.tolist(),TL2.tolist(),TL3.tolist(),TL4.tolist(),TL5.tolist(),TL6.tolist()]) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' split into testing and training sets '''\n",
    "len(ins)\n",
    "split = 0.7\n",
    "Ntrain = int(round(len(ins)*split,0))\n",
    "\n",
    "train_ins = ins[:Ntrain]\n",
    "test_ins = ins[Ntrain:]\n",
    "train_T = targs[:Ntrain]\n",
    "test_T = targs[Ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the model of GRU\n",
    "# Keras imports \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM,GRU, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_neurons = 1\n",
    "hidden_neurons = 1\n",
    " \n",
    "model = Sequential()  \n",
    "model.add(GRU(output_dim=hidden_neurons, input_dim= in_neurons, return_sequences=True, consume_less='gpu')) \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer= 'rmsprop' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s - loss: 16.5830 - val_loss: 10.8487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f2d902f98>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' train this fella '''\n",
    "model.fit(np.reshape(train_ins,(len(train_ins),np.shape(train_ins)[1],1) ), np.reshape(train_T,(len(train_ins),np.shape(train_ins)[1],1) ), batch_size=1, nb_epoch = 100, validation_split=0.1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Real  Predicted\n",
      "0      0   0.007264\n",
      "1      0   0.013209\n",
      "2      0   0.018086\n",
      "3      0   0.022092\n",
      "4      0   0.025389\n",
      "5      0   0.028105\n",
      "6      0   0.030345\n",
      "7      0   0.032193\n",
      "8      0   0.033720\n",
      "9      0   0.034981\n",
      "10     0   0.036024\n",
      "11     0   0.036886\n",
      "12     0   0.543951\n",
      "13     0   0.497786\n",
      "14     1   0.452059\n",
      "15     0   0.546196\n",
      "16     0   0.500032\n",
      "17     1   0.454264\n",
      "18     1   0.546123\n",
      "19     1   0.542265\n",
      "20     1   0.542456\n",
      "21     0   0.542447\n",
      "22     1   0.496282\n",
      "23     0   0.544554\n",
      "24     0   0.498389\n",
      "25     0   0.452651\n",
      "26     1   0.408179\n",
      "27     1   0.547465\n",
      "28     1   0.542207\n",
      "29     1   0.542459\n",
      "30     0   0.542447\n",
      "31     1   0.496282\n",
      "32     1   0.544554\n",
      "33     1   0.542342\n",
      "34     0   0.542453\n",
      "35     0   0.496288\n",
      "36     1   0.450590\n",
      "37     1   0.546245\n",
      "38     1   0.542259\n",
      "39     0   0.542457\n",
      "40     0   0.496292\n",
      "41     0   0.450594\n",
      "42     1   0.406198\n",
      "43     0   0.547514\n",
      "44     0   0.501351\n",
      "45     0   0.455560\n",
      "46     0   0.410982\n",
      "47     0   0.368370\n",
      "48     0   0.328332\n",
      "49     0   0.291312\n",
      "50     1   0.257584\n",
      "51     0   0.549109\n"
     ]
    }
   ],
   "source": [
    "Tshape = np.shape(train_ins)[1]\n",
    "predicted = model.predict(np.reshape(test_ins,(np.shape(test_T)[0],Tshape,1)))\n",
    "\n",
    "preds = pd.DataFrame()\n",
    "preds['Real'] = np.reshape(test_T[1],(Tshape) )\n",
    "preds['Predicted'] = np.reshape(predicted[1],(Tshape) )\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INP = win_series('EnVyUs','G2')\n",
    "predicted = model.predict(np.reshape(np.array(INP) , (2,len(INP[0]),1)) )[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00726403],\n",
       "       [ 0.01320932],\n",
       "       [ 0.54285729],\n",
       "       [ 0.54242665],\n",
       "       [ 0.54244822],\n",
       "       [ 0.54244715],\n",
       "       [ 0.49628255],\n",
       "       [ 0.45058441],\n",
       "       [ 0.40618879],\n",
       "       [ 0.36383224],\n",
       "       [ 0.32410753],\n",
       "       [ 0.5488987 ],\n",
       "       [ 0.54221153],\n",
       "       [ 0.54245901],\n",
       "       [ 0.54244661],\n",
       "       [ 0.49628198]], dtype=float32)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Real  Predicted\n",
      "0      1   0.542201\n",
      "1      1   0.542459\n",
      "2      1   0.542447\n",
      "3      1   0.542447\n",
      "4      1   0.542447\n",
      "5      0   0.496283\n",
      "6      0   0.450584\n",
      "7      1   0.546245\n",
      "8      1   0.542259\n",
      "9      0   0.496094\n",
      "10     1   0.544562\n",
      "11     1   0.542341\n",
      "12     1   0.542453\n",
      "13     1   0.542447\n",
      "14     1   0.542447\n"
     ]
    }
   ],
   "source": [
    "INP = win_series('EnVyUs','HellRaisers')\n",
    "\n",
    "predicted = model.predict(np.reshape(np.array(INP) , (2,len(INP[0]),1)) )[0]\n",
    "TTshape = len(predicted)\n",
    "preds = pd.DataFrame()\n",
    "preds['Real'] = np.reshape(INP[0],(TTshape) )\n",
    "preds['Predicted'] = np.reshape(predicted,(TTshape) )\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
